{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5114cfec-fa9a-4de0-8b26-99885c886d86",
   "metadata": {},
   "source": [
    "# **SO SÁNH MỨC GIỐNG NHAU GIỮA HAI CÂU VỀ MẶT NGỮ NGHĨA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd47f89-2ae6-4a6d-ba56-c44ab9e5e8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    ":dep candle-core = { version = \"0.9.1\", features = [\"cuda\", \"cudnn\"] }\n",
    ":dep candle-nn = { version = \"0.9.1\", features = [\"cuda\", \"cudnn\"] }\n",
    ":dep candle-transformers = { version = \"0.9.1\", features = [\"cuda\", \"cudnn\"] }\n",
    ":dep hf-hub = { version = \"0.4.3\", features = [\"native-tls\", \"tokio\"] }\n",
    ":dep serde_json = \"1.0.145\"\n",
    ":dep tokenizers = \"0.22.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf34d921-8844-4a68-9083-2d98d9be613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "use candle_core::{DType, Device, Tensor, IndexOp};\n",
    "use candle_nn::VarBuilder;\n",
    "use candle_transformers::models::bert::{BertModel, Config as BertConfig};\n",
    "use hf_hub::{api::sync::ApiBuilder, Repo, RepoType};\n",
    "use tokenizers::{\n",
    "    DecoderWrapper, ModelWrapper, Tokenizer\n",
    "    PostProcessorWrapper, PreTokenizerWrapper,\n",
    "    TokenizerImpl, NormalizerWrapper\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82550c35-f829-44af-b15e-9a97146783bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub fn build_model_and_tokenizer(\n",
    "    model_id: String, revision: String, device: &Device\n",
    ") -> Result<(BertModel, Tokenizer), Box<dyn std::error::Error>>\n",
    "{\n",
    "    // [01]\n",
    "    let access_token = std::env::var(\"HF_TOKEN\").map_err(|e| format!(\"{e}\"))?;\n",
    "    let api = ApiBuilder::new()\n",
    "        .with_progress(true)\n",
    "        .with_token(Some(access_token))\n",
    "        .build()?;\n",
    "\n",
    "    // [02]\n",
    "    let repo = Repo::with_revision(model_id, RepoType::Model, revision);\n",
    "    let api = api.repo(repo);\n",
    "    let config_file = api.get(\"config.json\")?;\n",
    "    let tokenizer_file = api.get(\"tokenizer.json\")?;\n",
    "\n",
    "    // [03]\n",
    "    let config: String = std::fs::read_to_string(config_file)?;\n",
    "    let config: BertConfig = serde_json::from_str(&config)?;\n",
    "\n",
    "    // [04]\n",
    "    let tokenizer: Tokenizer = Tokenizer::from_file(tokenizer_file)\n",
    "                                                .map_err(|e| format!(\"{e}\"))?;\n",
    "    // [05]\n",
    "    let vb = match api.get(\"model.safetensors\") {\n",
    "        Ok(path) => {\n",
    "            println!(\"Sử dụng SafeTensors: {:?}\", path);\n",
    "            unsafe {\n",
    "                VarBuilder::from_mmaped_safetensors(\n",
    "                    &[path], DType::F32, device\n",
    "                )\n",
    "            }\n",
    "        },\n",
    "        Err(_) => {\n",
    "            let path = api.get(\"pytorch_model.bin\")?;\n",
    "            println!(\"Sử dụng PyTorch Binary: {:?}\", path);\n",
    "            VarBuilder::from_pth(&path, DType::F32, device)\n",
    "        }\n",
    "    }?;\n",
    "\n",
    "    // [06]\n",
    "    let model = BertModel::load(vb, &config)?;\n",
    "    \n",
    "    Ok((model, tokenizer))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4be46b-19c9-452f-ba75-f99e5b144dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub fn gen_embeddings_mean_pooling(\n",
    "    tokenizer: &mut TokenizerImpl<\n",
    "        ModelWrapper, NormalizerWrapper,\n",
    "        PreTokenizerWrapper, PostProcessorWrapper, DecoderWrapper,\n",
    "    >,\n",
    "    model: &BertModel,\n",
    "    prompt: &str,\n",
    ") -> Result<Tensor, Box<dyn std::error::Error>> {\n",
    "    // [01]\n",
    "    let device = &model.device;\n",
    "\n",
    "    // [02]\n",
    "    let tokens: Vec<u32> = tokenizer.encode(prompt, true)\n",
    "        .map_err(|e| format!(\"{e}\"))?\n",
    "        .get_ids()\n",
    "        .to_vec();\n",
    "\n",
    "    // [03]\n",
    "    let token_ids = Tensor::new(&tokens[..], device)?.unsqueeze(0)?;\n",
    "    //println!(\"-- {:?}\\n{}\", token_ids.shape(), token_ids.narrow(1, 0, 5)?);\n",
    "\n",
    "    // [04]\n",
    "    let token_type_ids = token_ids.zeros_like()?;\n",
    "    /*println!(\"-- {:?}\\n{}\",\n",
    "        token_type_ids.shape(), token_type_ids.narrow(1, 0, 5)?\n",
    "    );*/\n",
    "\n",
    "    let emb: Tensor = model.forward(&token_ids, &token_type_ids, None)?;\n",
    "    //println!(\"Trước pooling -- {:?}\\n{}\", emb.shape(), emb.narrow(1, 0, 5)?);\n",
    "\n",
    "    // [05]\n",
    "    let (_n_sentence, n_tokens, _hidden_size) = emb.dims3()?;\n",
    "    let emb: Tensor = (emb.sum(1)? / (n_tokens as f64))?;\n",
    "    //println!(\"Sau pooling -- {:?}\\n{}\", emb.shape(), emb.narrow(1, 0, 5)?);\n",
    "\n",
    "    // [06]\n",
    "    let normalized_emb = normalize_l2(&emb)?;\n",
    "    /*println!(\"-- {:?}\\n{}\",\n",
    "        normalized_emb.shape(), normalized_emb.narrow(1, 0, 5)?\n",
    "    );*/\n",
    "\n",
    "    Ok(normalized_emb)\n",
    "}\n",
    "\n",
    "/// Hàm thực hiện chuẩn hóa một ten-xơ bằng phương thức L2-Norm\n",
    "pub fn normalize_l2(v: &Tensor) -> Result<Tensor, Box<dyn std::error::Error>> {\n",
    "    Ok(v.broadcast_div(&v.sqr()?.sum_keepdim(1)?.sqrt()?)?)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df4cefb9-f180-4093-a7eb-129c3fe8cd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sử dụng SafeTensors: \"/home/trinhtuan/.cache/huggingface/hub/models--sentence-transformers--paraphrase-multilingual-mpnet-base-v2/snapshots/4328cf26390c98c5e3c738b4460a05b95f4911f5/model.safetensors\"\n",
      "-----\n",
      "| this is a Rust programming teaching book\n",
      "| đây là một cuốn sách dạy lập trình Rust\n",
      "-----> Mức độ giống nhau: 0.95408356\n",
      "-----\n",
      "| tôi rất thích đi biển vào mùa hè\n",
      "| I like going to the beach in the summer very much\n",
      "-----> Mức độ giống nhau: 0.9099325\n",
      "-----\n",
      "| học lập trình sẽ phát triển tư duy lô gíc\n",
      "| tư duy lô gíc sẽ được cải thiện khi học lập trình\n",
      "-----> Mức độ giống nhau: 0.6341647\n",
      "-----\n",
      "| hôm qua, thủ tướng đã sang thăm Cuba\n",
      "| The Priminister visited Cuba yesterday\n",
      "-----> Mức độ giống nhau: 0.89707315\n",
      "-----\n",
      "| hôm qua, thủ tướng đã sang thăm Cuba\n",
      "| hôm qua, người đứng đầu nhà nước đã sang thăm Cuba\n",
      "-----> Mức độ giống nhau: 0.9215536\n",
      "-----\n",
      "| cảnh sát đang truy đuổi bọn tội phạm\n",
      "| bọn tội phạm đang truy đuổi cảnh sát\n",
      "-----> Mức độ giống nhau: 0.8732573\n",
      "-----\n",
      "| bọn tội phạm đang bị cảnh sát truy đuổi\n",
      "| cảnh sát đang đuổi bắt bọn tội phạm\n",
      "-----> Mức độ giống nhau: 0.8609685\n",
      "-----\n",
      "| the police are chasing the criminals\n",
      "| cảnh sát không hề truy đuổi bọn tội phạm\n",
      "-----> Mức độ giống nhau: 0.46558708\n",
      "-----\n",
      "| khi xảy ra rủi ro, bạn sẽ được chi trả quyền lợi bảo hiểm\n",
      "| bảo hiểm đặc biệt có ý nghĩa khi bạn gặp rủi ro\n",
      "-----> Mức độ giống nhau: 0.6916312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const MODEL: &str =\n",
    "    \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\";\n",
    "const REVISION: &str = \"main\";\n",
    "\n",
    "const SENTENCES: [[&str; 2]; 9] = [\n",
    "    [\"this is a Rust programming teaching book\",\n",
    "    \"đây là một cuốn sách dạy lập trình Rust\"],\n",
    "    [\"tôi rất thích đi biển vào mùa hè\",\n",
    "    \"I like going to the beach in the summer very much\"],\n",
    "    [\"học lập trình sẽ phát triển tư duy lô gíc\",\n",
    "    \"tư duy lô gíc sẽ được cải thiện khi học lập trình\"],\n",
    "    [\"hôm qua, thủ tướng đã sang thăm Cuba\",\n",
    "    \"The Priminister visited Cuba yesterday\"],\n",
    "    [\"hôm qua, thủ tướng đã sang thăm Cuba\",\n",
    "    \"hôm qua, người đứng đầu nhà nước đã sang thăm Cuba\"],\n",
    "    [\"cảnh sát đang truy đuổi bọn tội phạm\",\n",
    "    \"bọn tội phạm đang truy đuổi cảnh sát\"],\n",
    "    [\"bọn tội phạm đang bị cảnh sát truy đuổi\",\n",
    "    \"cảnh sát đang đuổi bắt bọn tội phạm\"],\n",
    "    [\"the police are chasing the criminals\",\n",
    "    \"cảnh sát không hề truy đuổi bọn tội phạm\"],\n",
    "    [\"khi xảy ra rủi ro, bạn sẽ được chi trả quyền lợi bảo hiểm\",\n",
    "    \"bảo hiểm đặc biệt có ý nghĩa khi bạn gặp rủi ro\"]\n",
    "];\n",
    "\n",
    "{\n",
    "    // [01]\n",
    "    let device = match Device::cuda_if_available(0) {\n",
    "        Ok(cuda) => cuda,\n",
    "        _ => Device::Cpu\n",
    "    };\n",
    "\n",
    "    // [02]\n",
    "    let (model, mut tokenizer) = build_model_and_tokenizer(\n",
    "                                    MODEL.to_string(), REVISION.to_string(),\n",
    "                                    &device)?;\n",
    "    // [03]\n",
    "    let tokenizer = tokenizer\n",
    "        .with_padding(None)\n",
    "        .with_truncation(None)\n",
    "        .map_err(|e| format!(\"Lỗi cấu hình tokenizer: {e}\"))?;\n",
    "    /*\n",
    "    let test_tokenizer = tokenizer.encode(SENTENCES[0][1], false)?;\n",
    "    println!(\"{:?}\", test_tokenizer.get_tokens());\n",
    "    println!(\"{:?}\", test_tokenizer.get_ids());*/\n",
    "    \n",
    "    // [04]\n",
    "    let mut sentences_similarity_mean = Vec::<f32>::new();\n",
    "    for s in SENTENCES {\n",
    "        let emb1 = gen_embeddings_mean_pooling(tokenizer, &model, s[0])?;\n",
    "        let emb2 = gen_embeddings_mean_pooling(tokenizer, &model, s[1])?;\n",
    "        //println!(\"emb1: {:?}\", emb1);\n",
    "        //println!(\"emb2: {:?}\", emb2);\n",
    "\n",
    "        let sum = &emb1\n",
    "            .matmul(&emb2.transpose(0, 1)?)?.sum_all()?\n",
    "            .to_scalar::<f32>()?;\n",
    "\n",
    "        sentences_similarity_mean.push(*sum);\n",
    "    }\n",
    "\n",
    "    // [05]\n",
    "    for (i, s) in SENTENCES.iter().enumerate() {\n",
    "        println!(\"-----\");\n",
    "        println!(\"| {}\", s[0]);\n",
    "        println!(\"| {}\", s[1]);\n",
    "        println!(\"-----> Mức độ giống nhau: {}\",\n",
    "            sentences_similarity_mean.get(i).unwrap()\n",
    "        );\n",
    "    }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
